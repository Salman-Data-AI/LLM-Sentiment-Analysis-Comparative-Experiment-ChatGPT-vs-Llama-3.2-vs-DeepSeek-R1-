# LLM Sentimentâ€‘Analysis Comparative Experiment

> ChatGPT (gptâ€‘3.5â€‘turbo)Â Â· LlamaÂ 3.2 (8â€¯B, Ollama)Â Â· DeepSeekâ€‘R1Â 1.5â€¯B (Ollama)

![Comparison](./ChatGPT%20vs.%20Llama3.2%20vs.%20DeepSeek%20image.png)

### ğŸ“ŒÂ Goal
Measure accuracy, qualitative depth, and latency when the **same financialâ€‘news feed** is processed by three different LLM stacks. 
The financial news will be sourced from feeds.finance.yahoo.com.

### ğŸ”§Â Tech stack
| Layer | Tool |
|-------|------|
| Scraper | `feedparser` + `BeautifulSoup` |
| Local models | `Ollama` (LlamaÂ 3.2 Q4_0 Â· DeepSeekâ€‘R1Â 1.5â€¯B Q4_0) |
| Cloud model | OpenAI `gptâ€‘3.5â€‘turbo` |

### The Process
- Procured financial headlines and news from yahoo finance.
- Used ChatGPT, Llama3.2 and DeepSeek individually to generate summary of the obtained content. 
- The results were put in a tabular format with the columns: date, headline, summary, sentiment, url.
- The sentiment is classified into bullish, neutral and bearish.

### ğŸ—‚Â Findings

![image](https://github.com/user-attachments/assets/da4bd028-f2e3-433b-baa2-e280cc9a9449)

### ğŸ“Â Takeâ€‘aways

- For quick dashboards, ChatGPT 3.5 offers the best latencyâ€‘toâ€‘cost ratio.
- DeepSeek returns richer narratives yet is still faster than LlamaÂ 3.2 on 8â€¯GB RAM.
- Local models shine where privacy is key or token limits blow up costs.
