# LLM Sentimentâ€‘Analysis Comparative Experiment

> ChatGPT (gptâ€‘3.5â€‘turbo)Â Â· LlamaÂ 3.2 (8â€¯B, Ollama)Â Â· DeepSeekâ€‘R1Â 1.5â€¯B (Ollama)

![Comparison](./ChatGPT%20vs.%20Llama3.2%20vs.%20DeepSeek%20image.png)

### ğŸ“ŒÂ Goal
Measure accuracy, qualitative depth, and latency when the **same financialâ€‘news feed** is processed by three different LLM stacks. 
The financial news will be sourced from feeds.finance.yahoo.com.

### ğŸ”§Â Tech stack
| Layer | Tool |
|-------|------|
| Scraper | `feedparser` + `BeautifulSoup` |
| Local models | `Ollama` (LlamaÂ 3.2 Q4_0 Â· DeepSeekâ€‘R1Â 1.5â€¯B Q4_0) |
| Cloud model | OpenAI `gptâ€‘3.5â€‘turbo` |

### ğŸ—‚Â Findings

![Comparison Results](./Comparison%20Results.JPG)

### ğŸ“Â Takeâ€‘aways

- For quick dashboards, ChatGPT 3.5 offers the best latencyâ€‘toâ€‘cost ratio.
- DeepSeek returns richer narratives yet is still faster than LlamaÂ 3.2 on 8â€¯GB RAM.
- Local models shine where privacy is key or token limits blow up costs.
